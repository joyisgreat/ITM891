{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Problem 1 - CIFAR-100 Classification\n",
        "Please change the Edit>Notebook>Hardware Accelerator settings in Colab from None to GPU."
      ],
      "metadata": {
        "id": "Nqs_W3rYhPu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the GPU information\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "4cRjYoVgdL3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55f805c-dc93-42cf-bc28-27046e71b6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 22 19:46:08 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0    32W /  70W |   7699MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-100 classification\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 256\n",
        "\n",
        "# Define the transform to normalize the data\n",
        "transform = torchvision.transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Resize to 224x224 (height x width)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                          std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Load the training set\n",
        "train_set = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "# Load the test set\n",
        "test_set = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# Create data loaders to load the data in batches\n",
        "train_loader =  torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "QKniVJKFdUPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e19b8cc-5ffe-42d1-ed8a-735ab2c5761d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "# Use pretrained weights\n",
        "net = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1).cuda()"
      ],
      "metadata": {
        "id": "XuNVoTKJdioK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss and the optimizer\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torch.nn as nn\n",
        "\n",
        "epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = CosineAnnealingLR(optimizer, epochs, eta_min=0, last_epoch=- 1, verbose=False)"
      ],
      "metadata": {
        "id": "hG6WwbKddtgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the network\n",
        "acc_list = []\n",
        "for epoch in range(epochs):  # Loop over the dataset multiple times\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # Get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 0:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "    scheduler.step()\n",
        "            \n",
        "    # Test the network\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # Since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            # Calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            \n",
        "            # The class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc_list.append(100 * correct // total)\n",
        "\n",
        "    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "mB_sv3UDdweZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eaa39c2-dbbe-4386-c275-008505ad3ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.005\n",
            "[1,    11] loss: 0.041\n",
            "[1,    21] loss: 0.026\n",
            "[1,    31] loss: 0.020\n",
            "[1,    41] loss: 0.017\n",
            "[1,    51] loss: 0.016\n",
            "[1,    61] loss: 0.014\n",
            "[1,    71] loss: 0.013\n",
            "[1,    81] loss: 0.012\n",
            "[1,    91] loss: 0.011\n",
            "[1,   101] loss: 0.010\n",
            "[1,   111] loss: 0.010\n",
            "[1,   121] loss: 0.009\n",
            "[1,   131] loss: 0.009\n",
            "[1,   141] loss: 0.008\n",
            "[1,   151] loss: 0.008\n",
            "[1,   161] loss: 0.008\n",
            "[1,   171] loss: 0.008\n",
            "[1,   181] loss: 0.007\n",
            "[1,   191] loss: 0.007\n",
            "Accuracy of the network on the 10000 test images: 59 %\n",
            "[2,     1] loss: 0.001\n",
            "[2,    11] loss: 0.006\n",
            "[2,    21] loss: 0.006\n",
            "[2,    31] loss: 0.005\n",
            "[2,    41] loss: 0.005\n",
            "[2,    51] loss: 0.005\n",
            "[2,    61] loss: 0.005\n",
            "[2,    71] loss: 0.005\n",
            "[2,    81] loss: 0.005\n",
            "[2,    91] loss: 0.005\n",
            "[2,   101] loss: 0.005\n",
            "[2,   111] loss: 0.005\n",
            "[2,   121] loss: 0.005\n",
            "[2,   131] loss: 0.005\n",
            "[2,   141] loss: 0.005\n",
            "[2,   151] loss: 0.005\n",
            "[2,   161] loss: 0.005\n",
            "[2,   171] loss: 0.005\n",
            "[2,   181] loss: 0.005\n",
            "[2,   191] loss: 0.005\n",
            "Accuracy of the network on the 10000 test images: 69 %\n",
            "[3,     1] loss: 0.000\n",
            "[3,    11] loss: 0.003\n",
            "[3,    21] loss: 0.003\n",
            "[3,    31] loss: 0.003\n",
            "[3,    41] loss: 0.003\n",
            "[3,    51] loss: 0.003\n",
            "[3,    61] loss: 0.003\n",
            "[3,    71] loss: 0.003\n",
            "[3,    81] loss: 0.003\n",
            "[3,    91] loss: 0.003\n",
            "[3,   101] loss: 0.003\n",
            "[3,   111] loss: 0.003\n",
            "[3,   121] loss: 0.003\n",
            "[3,   131] loss: 0.003\n",
            "[3,   141] loss: 0.003\n",
            "[3,   151] loss: 0.003\n",
            "[3,   161] loss: 0.003\n",
            "[3,   171] loss: 0.003\n",
            "[3,   181] loss: 0.003\n",
            "[3,   191] loss: 0.003\n",
            "Accuracy of the network on the 10000 test images: 72 %\n",
            "[4,     1] loss: 0.000\n",
            "[4,    11] loss: 0.002\n",
            "[4,    21] loss: 0.002\n",
            "[4,    31] loss: 0.002\n",
            "[4,    41] loss: 0.001\n",
            "[4,    51] loss: 0.002\n",
            "[4,    61] loss: 0.001\n",
            "[4,    71] loss: 0.002\n",
            "[4,    81] loss: 0.001\n",
            "[4,    91] loss: 0.001\n",
            "[4,   101] loss: 0.002\n",
            "[4,   111] loss: 0.001\n",
            "[4,   121] loss: 0.001\n",
            "[4,   131] loss: 0.001\n",
            "[4,   141] loss: 0.002\n",
            "[4,   151] loss: 0.001\n",
            "[4,   161] loss: 0.002\n",
            "[4,   171] loss: 0.002\n",
            "[4,   181] loss: 0.002\n",
            "[4,   191] loss: 0.002\n",
            "Accuracy of the network on the 10000 test images: 74 %\n",
            "[5,     1] loss: 0.000\n",
            "[5,    11] loss: 0.001\n",
            "[5,    21] loss: 0.001\n",
            "[5,    31] loss: 0.001\n",
            "[5,    41] loss: 0.001\n",
            "[5,    51] loss: 0.001\n",
            "[5,    61] loss: 0.001\n",
            "[5,    71] loss: 0.001\n",
            "[5,    81] loss: 0.001\n",
            "[5,    91] loss: 0.001\n",
            "[5,   101] loss: 0.001\n",
            "[5,   111] loss: 0.001\n",
            "[5,   121] loss: 0.001\n",
            "[5,   131] loss: 0.001\n",
            "[5,   141] loss: 0.001\n",
            "[5,   151] loss: 0.001\n",
            "[5,   161] loss: 0.001\n",
            "[5,   171] loss: 0.001\n",
            "[5,   181] loss: 0.001\n",
            "[5,   191] loss: 0.001\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "[6,     1] loss: 0.000\n",
            "[6,    11] loss: 0.000\n",
            "[6,    21] loss: 0.000\n",
            "[6,    31] loss: 0.000\n",
            "[6,    41] loss: 0.000\n",
            "[6,    51] loss: 0.000\n",
            "[6,    61] loss: 0.000\n",
            "[6,    71] loss: 0.000\n",
            "[6,    81] loss: 0.000\n",
            "[6,    91] loss: 0.000\n",
            "[6,   101] loss: 0.000\n",
            "[6,   111] loss: 0.000\n",
            "[6,   121] loss: 0.000\n",
            "[6,   131] loss: 0.000\n",
            "[6,   141] loss: 0.000\n",
            "[6,   151] loss: 0.000\n",
            "[6,   161] loss: 0.000\n",
            "[6,   171] loss: 0.000\n",
            "[6,   181] loss: 0.000\n",
            "[6,   191] loss: 0.000\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "[7,     1] loss: 0.000\n",
            "[7,    11] loss: 0.000\n",
            "[7,    21] loss: 0.000\n",
            "[7,    31] loss: 0.000\n",
            "[7,    41] loss: 0.000\n",
            "[7,    51] loss: 0.000\n",
            "[7,    61] loss: 0.000\n",
            "[7,    71] loss: 0.000\n",
            "[7,    81] loss: 0.000\n",
            "[7,    91] loss: 0.000\n",
            "[7,   101] loss: 0.000\n",
            "[7,   111] loss: 0.000\n",
            "[7,   121] loss: 0.000\n",
            "[7,   131] loss: 0.000\n",
            "[7,   141] loss: 0.000\n",
            "[7,   151] loss: 0.000\n",
            "[7,   161] loss: 0.000\n",
            "[7,   171] loss: 0.000\n",
            "[7,   181] loss: 0.000\n",
            "[7,   191] loss: 0.000\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "[8,     1] loss: 0.000\n",
            "[8,    11] loss: 0.000\n",
            "[8,    21] loss: 0.000\n",
            "[8,    31] loss: 0.000\n",
            "[8,    41] loss: 0.000\n",
            "[8,    51] loss: 0.000\n",
            "[8,    61] loss: 0.000\n",
            "[8,    71] loss: 0.000\n",
            "[8,    81] loss: 0.000\n",
            "[8,    91] loss: 0.000\n",
            "[8,   101] loss: 0.000\n",
            "[8,   111] loss: 0.000\n",
            "[8,   121] loss: 0.000\n",
            "[8,   131] loss: 0.000\n",
            "[8,   141] loss: 0.000\n",
            "[8,   151] loss: 0.000\n",
            "[8,   161] loss: 0.000\n",
            "[8,   171] loss: 0.000\n",
            "[8,   181] loss: 0.000\n",
            "[8,   191] loss: 0.000\n",
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "[9,     1] loss: 0.000\n",
            "[9,    11] loss: 0.000\n",
            "[9,    21] loss: 0.000\n",
            "[9,    31] loss: 0.000\n",
            "[9,    41] loss: 0.000\n",
            "[9,    51] loss: 0.000\n",
            "[9,    61] loss: 0.000\n",
            "[9,    71] loss: 0.000\n",
            "[9,    81] loss: 0.000\n",
            "[9,    91] loss: 0.000\n",
            "[9,   101] loss: 0.000\n",
            "[9,   111] loss: 0.000\n",
            "[9,   121] loss: 0.000\n",
            "[9,   131] loss: 0.000\n",
            "[9,   141] loss: 0.000\n",
            "[9,   151] loss: 0.000\n",
            "[9,   161] loss: 0.000\n",
            "[9,   171] loss: 0.000\n",
            "[9,   181] loss: 0.000\n",
            "[9,   191] loss: 0.000\n",
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "[10,     1] loss: 0.000\n",
            "[10,    11] loss: 0.000\n",
            "[10,    21] loss: 0.000\n",
            "[10,    31] loss: 0.000\n",
            "[10,    41] loss: 0.000\n",
            "[10,    51] loss: 0.000\n",
            "[10,    61] loss: 0.000\n",
            "[10,    71] loss: 0.000\n",
            "[10,    81] loss: 0.000\n",
            "[10,    91] loss: 0.000\n",
            "[10,   101] loss: 0.000\n",
            "[10,   111] loss: 0.000\n",
            "[10,   121] loss: 0.000\n",
            "[10,   131] loss: 0.000\n",
            "[10,   141] loss: 0.000\n",
            "[10,   151] loss: 0.000\n",
            "[10,   161] loss: 0.000\n",
            "[10,   171] loss: 0.000\n",
            "[10,   181] loss: 0.000\n",
            "[10,   191] loss: 0.000\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-100 classification\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 256\n",
        "\n",
        "# Define the transform to normalize the data\n",
        "transform = torchvision.transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Resize to 224x224 (height x width)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                          std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Load the training set\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "# Load the test set\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# Create data loaders to load the data in batches\n",
        "train_loader =  torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ff2990-cc94-4290-ecd9-9b604c31c6ff",
        "id": "gIjVdX4ee1Qp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 104726089.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "dataiter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWFy8LsCsKT_",
        "outputId": "51c988c6-4b74-4744-9ea9-efccc74f5e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader._MultiProcessingDataLoaderIter at 0x7eff6d30a250>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "id": "8wMiBjYUsN_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70E1rJRVsRdf",
        "outputId": "f732900e-27ad-459a-aff1-5b90f4761321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 4, 3, 8, 3, 5, 5, 5, 5, 6, 9, 4, 3, 8, 4, 9, 6, 7, 6, 0, 3, 9, 0, 0,\n",
              "        0, 8, 0, 5, 3, 9, 8, 2, 3, 7, 4, 5, 5, 9, 5, 6, 8, 9, 7, 9, 2, 9, 1, 6,\n",
              "        6, 2, 6, 1, 4, 5, 5, 2, 6, 3, 7, 2, 1, 3, 3, 2, 6, 9, 5, 5, 4, 1, 6, 9,\n",
              "        0, 1, 8, 3, 4, 2, 1, 8, 4, 1, 6, 7, 6, 6, 0, 5, 4, 5, 2, 6, 1, 1, 8, 0,\n",
              "        0, 3, 7, 7, 2, 5, 2, 3, 8, 0, 4, 7, 1, 3, 1, 4, 4, 7, 1, 1, 9, 7, 9, 4,\n",
              "        6, 5, 7, 2, 9, 0, 8, 4, 3, 5, 4, 0, 8, 4, 5, 2, 2, 8, 3, 2, 4, 5, 9, 2,\n",
              "        1, 6, 9, 4, 6, 2, 3, 8, 5, 4, 8, 7, 9, 6, 0, 2, 4, 3, 5, 4, 9, 8, 2, 9,\n",
              "        6, 3, 5, 2, 3, 6, 0, 4, 2, 9, 9, 6, 8, 1, 3, 6, 8, 2, 0, 6, 4, 1, 4, 4,\n",
              "        6, 9, 4, 2, 4, 2, 6, 9, 9, 9, 2, 6, 4, 2, 2, 3, 9, 0, 5, 2, 7, 9, 0, 0,\n",
              "        4, 7, 4, 4, 3, 0, 2, 8, 2, 4, 0, 8, 1, 7, 9, 8, 2, 9, 6, 1, 1, 5, 8, 3,\n",
              "        2, 4, 9, 4, 0, 0, 2, 0, 0, 7, 2, 9, 4, 7, 2, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "# Use pretrained weights\n",
        "net = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1).cuda()"
      ],
      "metadata": {
        "id": "Y8Y_5yJve1Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss and the optimizer\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torch.nn as nn\n",
        "\n",
        "epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = CosineAnnealingLR(optimizer, epochs, eta_min=0, last_epoch=- 1, verbose=False)"
      ],
      "metadata": {
        "id": "8SxeW07_e1Qs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}